{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf762515",
   "metadata": {},
   "source": [
    "## In this notebook, we will load and clean our data\n",
    " We are working with 10 files, but df_train_all_v1.parquet is the full training data set we can start with\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5774345d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core fact tables (sales data):\n",
    "#\t•\tdf2016_train.parquet (subset, probably for initial testing/competition baseline)\n",
    "#\t•\tdf_train_all_v1.parquet (full training set)\n",
    "#\t•\tdf_test.parquet, df_test_2022.parquet (test sets)\n",
    "#\t•\tsample_submission.parquet (submission format, not for analysis)\n",
    "\n",
    "# Supporting dimension tables (metadata & signals):\n",
    "#\t•\titems.parquet (item family, perishable flag, etc.)\n",
    "#\t•\tstores.parquet (store city, type, cluster)\n",
    "#\t•\ttransactions.parquet (daily transaction counts by store)\n",
    "#\t•\tholiday_events.parquet (dates + holiday flags)\n",
    "#\t•\toil.parquet (daily oil prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95f325b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add libraries to use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88eb7d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/angiediaz/CPSC4300/grocery-sales-forecasting/scripts\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1bd5343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in df_train_all_v1.parquet (main) + rest \n",
    "df_train = pd.read_parquet(\"../data/raw/df_train_all_v1.parquet\")\n",
    "df_items = pd.read_parquet(\"../data/raw/items.parquet\")\n",
    "df_stores = pd.read_parquet(\"../data/raw/stores.parquet\")\n",
    "\n",
    "df_holidays = pd.read_parquet(\"../data/raw/holiday_events.parquet\")\n",
    "df_oil = pd.read_parquet(\"../data/raw/oil.parquet\")\n",
    "df_transactions = pd.read_parquet(\"../data/raw/transactions.parquet\")\n",
    "\n",
    "\n",
    "#Extra datasets, not used for modeling just checking these are also good\n",
    "df_test = pd.read_parquet(\"../data/raw/df_test.parquet\")\n",
    "df_test_2022 = pd.read_parquet(\"../data/raw/df_test_2022.parquet\")\n",
    "df_sample_submission = pd.read_parquet(\"../data/raw/sample_submission.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff73dd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125497040, 5)\n",
      "date           datetime64[us]\n",
      "store_nbr               int64\n",
      "item_nbr                int64\n",
      "unit_sales            float64\n",
      "onpromotion              bool\n",
      "dtype: object\n",
      "date           0\n",
      "store_nbr      0\n",
      "item_nbr       0\n",
      "unit_sales     0\n",
      "onpromotion    0\n",
      "dtype: int64\n",
      "\n",
      "Number of duplicate rows: 0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125497040 entries, 0 to 125497039\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Dtype         \n",
      "---  ------       -----         \n",
      " 0   date         datetime64[us]\n",
      " 1   store_nbr    int64         \n",
      " 2   item_nbr     int64         \n",
      " 3   unit_sales   float64       \n",
      " 4   onpromotion  bool          \n",
      "dtypes: bool(1), datetime64[us](1), float64(1), int64(2)\n",
      "memory usage: 3.9 GB\n"
     ]
    }
   ],
   "source": [
    "#Check its shape, types and missing values\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_train.dtypes)\n",
    "print(df_train.isnull().sum())\n",
    "\n",
    "# Check duplicates\n",
    "dup_count = df_train.duplicated().sum()\n",
    "print(f\"\\nNumber of duplicate rows: {dup_count}\")\n",
    "\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cfea6ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'store_nbr', 'item_nbr', 'unit_sales', 'onpromotion'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4378e78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>103665</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>105574</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>105575</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>105577</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>105737</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125396207</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>1</td>\n",
       "      <td>2114812</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125396208</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>1</td>\n",
       "      <td>2116416</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125396209</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>1</td>\n",
       "      <td>2122188</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125396210</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>1</td>\n",
       "      <td>2122676</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125396211</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>1</td>\n",
       "      <td>2124052</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2562153 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                date  store_nbr  item_nbr  unit_sales  onpromotion\n",
       "578       2013-01-02          1    103665    1.098612        False\n",
       "579       2013-01-02          1    105574    2.197225        False\n",
       "580       2013-01-02          1    105575    2.772589        False\n",
       "581       2013-01-02          1    105577    1.098612        False\n",
       "582       2013-01-02          1    105737    1.098612        False\n",
       "...              ...        ...       ...         ...          ...\n",
       "125396207 2017-08-15          1   2114812    0.693147         True\n",
       "125396208 2017-08-15          1   2116416    0.693147        False\n",
       "125396209 2017-08-15          1   2122188    0.693147        False\n",
       "125396210 2017-08-15          1   2122676    1.098612        False\n",
       "125396211 2017-08-15          1   2124052    0.693147        False\n",
       "\n",
       "[2562153 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['store_nbr']==1]\n",
    "#not organized by str_nbr, but by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1c296bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date, store_nbr, item_nbr, unit_sales, onpromotion]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['unit_sales']<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4f02ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So after looking at the data, we can see that there are no missing values in the dataset\n",
    "# We can also see that the date column is already in datetime format\n",
    "# All the other columns have the correct type\n",
    "# This is a huge dataset, will need to be cautious with memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27485175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the other datasets for missing values and types\n",
    "\n",
    "def check_df(df, name):\n",
    "    print(f\"Checking {name}\")\n",
    "    print(df.shape)\n",
    "    print(df.dtypes)\n",
    "    print(df.isnull().sum())\n",
    "    print(df.info())\n",
    "    \n",
    "    # Check duplicates\n",
    "    dup_count = df.duplicated().sum()\n",
    "    print(f\"\\nNumber of duplicate rows: {dup_count}\")\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7283c3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking items\n",
      "(4100, 3)\n",
      "family        object\n",
      "class          int64\n",
      "perishable     int64\n",
      "dtype: object\n",
      "family        0\n",
      "class         0\n",
      "perishable    0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4100 entries, 96995 to 2134244\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   family      4100 non-null   object\n",
      " 1   class       4100 non-null   int64 \n",
      " 2   perishable  4100 non-null   int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 128.1+ KB\n",
      "None\n",
      "\n",
      "Number of duplicate rows: 3763\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_df(df_items, \"items\")\n",
    "\n",
    "\n",
    "#So in the items dataset, there are no missing values \n",
    "# the perishable column is an integer, but it should be a boolean \n",
    "# will match our onpromo column in the main dataset\n",
    "\n",
    "\n",
    "df_items[\"perishable\"] = df_items[\"perishable\"].astype(bool)\n",
    "\n",
    "df_items.head()\n",
    "\n",
    "#also the range runs from 96995 --> 2134244\n",
    "df_items = df_items.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df4df151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we have 4100 rows, but only 410 unique item_ids\n",
    "# We don't need to drop them though, only when we want a version for visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a01013ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking stores\n",
      "(54, 4)\n",
      "city       object\n",
      "state      object\n",
      "type       object\n",
      "cluster     int64\n",
      "dtype: object\n",
      "city       0\n",
      "state      0\n",
      "type       0\n",
      "cluster    0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 54 entries, 1 to 54\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   city     54 non-null     object\n",
      " 1   state    54 non-null     object\n",
      " 2   type     54 non-null     object\n",
      " 3   cluster  54 non-null     int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 2.1+ KB\n",
      "None\n",
      "\n",
      "Number of duplicate rows: 12\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Santo Domingo</td>\n",
       "      <td>Santo Domingo de los Tsachilas</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    city                           state type  cluster\n",
       "store_nbr                                                             \n",
       "1                  Quito                       Pichincha    D       13\n",
       "2                  Quito                       Pichincha    D       13\n",
       "3                  Quito                       Pichincha    D        8\n",
       "4                  Quito                       Pichincha    D        9\n",
       "5          Santo Domingo  Santo Domingo de los Tsachilas    D        4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_df(df_stores, \"stores\")\n",
    "\n",
    "df_stores.head()\n",
    "\n",
    "#Interesting thing in this dataset: cluster column\n",
    "# This is a grouping of stores based on sales and volume\n",
    "# Cluster is a grouping of stores with similar characteristics, but\n",
    "# the way it is calculated is not given, (could be similar sales patterns, demographics, or customer profiles)\n",
    "\n",
    "\n",
    "#address this in EDA, need to see if this could be a predictive value, if so, we keep, if not we drop\n",
    "\n",
    "#Some rows are duplicates in terms of city, state, type and cluster, but each store is uniquely identified by store_nbr\n",
    "# Duplicates do not affect merges with the main dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9625b56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    cluster          mean           sum  count\n",
      "0         1  4.134454e+06  1.240336e+07      3\n",
      "1         2  3.516715e+06  7.033429e+06      2\n",
      "2         3  2.641090e+06  1.848763e+07      7\n",
      "3         4  4.217771e+06  1.265331e+07      3\n",
      "4         5  8.145786e+06  8.145786e+06      1\n",
      "5         6  3.887535e+06  2.332521e+07      6\n",
      "6         7  2.071533e+06  4.143066e+06      2\n",
      "7         8  6.270882e+06  1.881265e+07      3\n",
      "8         9  4.043923e+06  8.087847e+06      2\n",
      "9        10  3.273356e+06  1.964013e+07      6\n",
      "10       11  5.126212e+06  1.537864e+07      3\n",
      "11       12  3.885254e+06  3.885254e+06      1\n",
      "12       13  4.370101e+06  1.748040e+07      4\n",
      "13       14  6.747228e+06  2.698891e+07      4\n",
      "14       15  2.823346e+06  1.411673e+07      5\n",
      "15       16  3.429654e+06  3.429654e+06      1\n",
      "16       17  5.715226e+06  5.715226e+06      1\n"
     ]
    }
   ],
   "source": [
    "# Average and total unit sales per cluster\n",
    "cluster_sales = (\n",
    "    df_train\n",
    "    .groupby(\"store_nbr\")[\"unit_sales\"].sum()\n",
    "    .reset_index()\n",
    "    .merge(df_stores[[\"cluster\"]], left_on=\"store_nbr\", right_index=True)\n",
    "    .groupby(\"cluster\")[\"unit_sales\"]\n",
    "    .agg([\"mean\", \"sum\", \"count\"])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(cluster_sales)\n",
    "\n",
    "\n",
    "# Don't see a clear pattern here, so we will keep the cluster column for now\n",
    "# Stores into 17 clusters, but initial analysis shows no strong or consistent relationship \n",
    "# between cluster and sales volume (average), may still be useful in modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5472066e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    cluster                                              state\n",
      "0         1                              [Guayas, Santa Elena]\n",
      "1         2                                            [Azuay]\n",
      "2         3  [Santo Domingo de los Tsachilas, Guayas, Los R...\n",
      "3         4     [Santo Domingo de los Tsachilas, Loja, El Oro]\n",
      "4         5                                        [Pichincha]\n",
      "5         6  [Pichincha, Santo Domingo de los Tsachilas, Gu...\n",
      "6         7                              [Chimborazo, Pastaza]\n",
      "7         8                                        [Pichincha]\n",
      "8         9                            [Pichincha, Tungurahua]\n",
      "9        10                     [Guayas, Los Rios, Esmeraldas]\n",
      "10       11                                [Pichincha, Manabi]\n",
      "11       12                                        [Pichincha]\n",
      "12       13                                [Pichincha, Manabi]\n",
      "13       14                            [Pichincha, Tungurahua]\n",
      "14       15           [Pichincha, Cotopaxi, Imbabura, Bolivar]\n",
      "15       16                                        [Pichincha]\n",
      "16       17                                           [Guayas]\n",
      "    cluster                           state  count\n",
      "0         1                          Guayas      2\n",
      "1         1                     Santa Elena      1\n",
      "2         2                           Azuay      2\n",
      "3         3                          El Oro      1\n",
      "4         3                          Guayas      3\n",
      "5         3                        Los Rios      1\n",
      "6         3                          Manabi      1\n",
      "7         3  Santo Domingo de los Tsachilas      1\n",
      "8         4                          El Oro      1\n",
      "9         4                            Loja      1\n",
      "10        4  Santo Domingo de los Tsachilas      1\n",
      "11        5                       Pichincha      1\n",
      "12        6                           Azuay      1\n",
      "13        6                          Guayas      1\n",
      "14        6                       Pichincha      3\n",
      "15        6  Santo Domingo de los Tsachilas      1\n",
      "16        7                      Chimborazo      1\n",
      "17        7                         Pastaza      1\n",
      "18        8                       Pichincha      3\n",
      "19        9                       Pichincha      1\n",
      "20        9                      Tungurahua      1\n",
      "21       10                      Esmeraldas      1\n",
      "22       10                          Guayas      4\n",
      "23       10                        Los Rios      1\n",
      "24       11                          Manabi      1\n",
      "25       11                       Pichincha      2\n",
      "26       12                       Pichincha      1\n",
      "27       13                          Manabi      1\n",
      "28       13                       Pichincha      3\n",
      "29       14                       Pichincha      3\n",
      "30       14                      Tungurahua      1\n",
      "31       15                         Bolivar      1\n",
      "32       15                        Cotopaxi      2\n",
      "33       15                        Imbabura      1\n",
      "34       15                       Pichincha      1\n",
      "35       16                       Pichincha      1\n",
      "36       17                          Guayas      1\n"
     ]
    }
   ],
   "source": [
    "#Checking to see if clusters have geographical patterns\n",
    "# Merge cluster info into stores table\n",
    "stores_clusters = df_stores[[\"city\", \"state\", \"cluster\"]]\n",
    "\n",
    "# See which clusters appear in which states\n",
    "cluster_state = stores_clusters.groupby(\"cluster\")[\"state\"].unique().reset_index()\n",
    "print(cluster_state)\n",
    "\n",
    "# Optional: count of stores per cluster per state\n",
    "cluster_state_count = stores_clusters.groupby([\"cluster\", \"state\"]).size().reset_index(name=\"count\")\n",
    "print(cluster_state_count)\n",
    "\n",
    "\n",
    "# Clusters do not appear to be strictly geographical, as many clusters span multiple states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "054d6121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking holidays\n",
      "(350, 6)\n",
      "date           object\n",
      "type           object\n",
      "locale         object\n",
      "locale_name    object\n",
      "description    object\n",
      "transferred      bool\n",
      "dtype: object\n",
      "date           0\n",
      "type           0\n",
      "locale         0\n",
      "locale_name    0\n",
      "description    0\n",
      "transferred    0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 350 entries, 0 to 349\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   date         350 non-null    object\n",
      " 1   type         350 non-null    object\n",
      " 2   locale       350 non-null    object\n",
      " 3   locale_name  350 non-null    object\n",
      " 4   description  350 non-null    object\n",
      " 5   transferred  350 non-null    bool  \n",
      "dtypes: bool(1), object(5)\n",
      "memory usage: 14.1+ KB\n",
      "None\n",
      "\n",
      "Number of duplicate rows: 0\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "      <th>locale</th>\n",
       "      <th>locale_name</th>\n",
       "      <th>description</th>\n",
       "      <th>transferred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-03-02</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Local</td>\n",
       "      <td>Manta</td>\n",
       "      <td>Fundacion de Manta</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-04-01</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Cotopaxi</td>\n",
       "      <td>Provincializacion de Cotopaxi</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-04-12</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Local</td>\n",
       "      <td>Cuenca</td>\n",
       "      <td>Fundacion de Cuenca</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-04-14</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Local</td>\n",
       "      <td>Libertad</td>\n",
       "      <td>Cantonizacion de Libertad</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-04-21</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Local</td>\n",
       "      <td>Riobamba</td>\n",
       "      <td>Cantonizacion de Riobamba</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     type    locale locale_name                    description  \\\n",
       "0  2012-03-02  Holiday     Local       Manta             Fundacion de Manta   \n",
       "1  2012-04-01  Holiday  Regional    Cotopaxi  Provincializacion de Cotopaxi   \n",
       "2  2012-04-12  Holiday     Local      Cuenca            Fundacion de Cuenca   \n",
       "3  2012-04-14  Holiday     Local    Libertad      Cantonizacion de Libertad   \n",
       "4  2012-04-21  Holiday     Local    Riobamba      Cantonizacion de Riobamba   \n",
       "\n",
       "   transferred  \n",
       "0        False  \n",
       "1        False  \n",
       "2        False  \n",
       "3        False  \n",
       "4        False  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_df(df_holidays, \"holidays\")\n",
    "\n",
    "df_holidays.head()\n",
    "\n",
    "\n",
    "# Transferred column: indicates if the holiday is observed on a different date than the actual holiday\n",
    "# Will be important when we want to flag the day customers actually get the holiday off (sales might spike on transferred days than official holiday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab9eb7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking transactions\n",
      "(83488, 3)\n",
      "date            object\n",
      "store_nbr        int64\n",
      "transactions     int64\n",
      "dtype: object\n",
      "date            0\n",
      "store_nbr       0\n",
      "transactions    0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 83488 entries, 0 to 83487\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   date          83488 non-null  object\n",
      " 1   store_nbr     83488 non-null  int64 \n",
      " 2   transactions  83488 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 1.9+ MB\n",
      "None\n",
      "\n",
      "Number of duplicate rows: 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_df(df_transactions, \"transactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5737bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date            datetime64[ns]\n",
      "store_nbr                int64\n",
      "transactions             int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Currently, date is an object (string), convert to datetime object\n",
    "\n",
    "df_transactions[\"date\"] = pd.to_datetime(df_transactions[\"date\"], format=\"%Y-%m-%d\")\n",
    "print(df_transactions.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1bfef621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking oil\n",
      "(1218, 2)\n",
      "date           object\n",
      "dcoilwtico    float64\n",
      "dtype: object\n",
      "date           0\n",
      "dcoilwtico    43\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1218 entries, 0 to 1217\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   date        1218 non-null   object \n",
      " 1   dcoilwtico  1175 non-null   float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 19.2+ KB\n",
      "None\n",
      "\n",
      "Number of duplicate rows: 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Purpose of oil dataset:\n",
    "# daily closing price of crude oil\n",
    "# Could be a proxy for broader economic conditions, as oil prices can influence transportation costs, consumer spending, and overall economic activity\n",
    "    # e.g transportation costs, seasonal/holiday shopping patterns \n",
    "\n",
    "check_df(df_oil, \"oil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "432efda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking oil after cleaning\n",
      "(1218, 2)\n",
      "date          datetime64[ns]\n",
      "dcoilwtico           float64\n",
      "dtype: object\n",
      "date          0\n",
      "dcoilwtico    1\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1218 entries, 0 to 1217\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   date        1218 non-null   datetime64[ns]\n",
      " 1   dcoilwtico  1217 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(1)\n",
      "memory usage: 19.2 KB\n",
      "None\n",
      "\n",
      "Number of duplicate rows: 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Date is also an object (string), convert to datetime object\n",
    "df_oil[\"date\"] = pd.to_datetime(df_oil[\"date\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "# 43 missing values in the dcoilwtico column\n",
    "df_oil[\"dcoilwtico\"] = df_oil[\"dcoilwtico\"].interpolate(method=\"linear\")\n",
    "\n",
    "\n",
    "check_df(df_oil, \"oil after cleaning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "639e6b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking oil after backfill\n",
      "(1218, 2)\n",
      "date          datetime64[ns]\n",
      "dcoilwtico           float64\n",
      "dtype: object\n",
      "date          0\n",
      "dcoilwtico    0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1218 entries, 0 to 1217\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   date        1218 non-null   datetime64[ns]\n",
      " 1   dcoilwtico  1218 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(1)\n",
      "memory usage: 19.2 KB\n",
      "None\n",
      "\n",
      "Number of duplicate rows: 0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2k/j9b6q32d02dgv4_bwwtm_lxh0000gn/T/ipykernel_90131/661833160.py:3: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_oil[\"dcoilwtico\"] = df_oil[\"dcoilwtico\"].fillna(method=\"bfill\")\n"
     ]
    }
   ],
   "source": [
    "df_oil[df_oil[\"dcoilwtico\"].isnull()]\n",
    "\n",
    "df_oil[\"dcoilwtico\"] = df_oil[\"dcoilwtico\"].fillna(method=\"bfill\")\n",
    "\n",
    "check_df(df_oil, \"oil after backfill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7515ef91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cfd1d7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned datasets saved to 'data' directory.\n"
     ]
    }
   ],
   "source": [
    "df_train.to_parquet(\"../data/df_train_cleaned.parquet\", engine=\"pyarrow\", index=False)\n",
    "df_oil.to_parquet(\"../data/df_oil_cleaned.parquet\", engine=\"pyarrow\", index=False)\n",
    "df_transactions.to_parquet(\"../data/df_train_cleaned.parquet\", engine=\"pyarrow\", index=False)\n",
    "df_holidays.to_parquet(\"../data/df_train_cleaned.parquet\", engine=\"pyarrow\", index=False)\n",
    "df_items.to_parquet(\"../data/df_items_cleaned.parquet\", engine=\"pyarrow\", index=False)\n",
    "df_stores.to_parquet(\"../data/df_stores_cleaned.parquet\", engine=\"pyarrow\", index=False)\n",
    "print(\"Cleaned datasets saved to 'data' directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f1746cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full df_train shape: (350, 6)\n",
      "Stratified sample shape: (0, 6)\n",
      "Saved stratified sample to:\n",
      "- ../data/df_train_stratified.csv\n",
      "- ../data/df_train_stratified.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2k/j9b6q32d02dgv4_bwwtm_lxh0000gn/T/ipykernel_90131/2024461829.py:20: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(frac=0.01, random_state=42))\n"
     ]
    }
   ],
   "source": [
    "# Stratified sampling to create a smaller representative dataset \n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Paths ---\n",
    "DATA_DIR = Path(\"../data\")        # adjust if needed\n",
    "OUTPUT_CSV = DATA_DIR / \"df_train_stratified.csv\"\n",
    "OUTPUT_PARQUET = DATA_DIR / \"df_train_stratified.parquet\"\n",
    "\n",
    "# --- Load cleaned full train dataset ---\n",
    "# Assuming you saved cleaned parquet in your notebook as df_train_cleaned.parquet\n",
    "df_train = pd.read_parquet(DATA_DIR / \"df_train_cleaned.parquet\", engine=\"pyarrow\")\n",
    "\n",
    "print(\"Full df_train shape:\", df_train.shape)\n",
    "\n",
    "# --- Stratified sample by date ---\n",
    "# Keeps 1% per date, preserving time series distribution\n",
    "stratified_sample = (\n",
    "    df_train.groupby(\"date\", group_keys=False)\n",
    "    .apply(lambda x: x.sample(frac=0.01, random_state=42))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"Stratified sample shape:\", stratified_sample.shape)\n",
    "\n",
    "# --- Save results ---\n",
    "stratified_sample.to_csv(OUTPUT_CSV, index=False)\n",
    "stratified_sample.to_parquet(OUTPUT_PARQUET, engine=\"pyarrow\", index=False)\n",
    "\n",
    "print(f\"Saved stratified sample to:\\n- {OUTPUT_CSV}\\n- {OUTPUT_PARQUET}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ada261c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Df Test\n",
      "(3370464, 2)\n",
      "id             int64\n",
      "onpromotion     bool\n",
      "dtype: object\n",
      "id             0\n",
      "onpromotion    0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 3370464 entries, (np.int64(1), np.int64(96995), Timestamp('2017-08-16 00:00:00')) to (np.int64(54), np.int64(2134244), Timestamp('2017-08-31 00:00:00'))\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Dtype\n",
      "---  ------       -----\n",
      " 0   id           int64\n",
      " 1   onpromotion  bool \n",
      "dtypes: bool(1), int64(1)\n",
      "memory usage: 41.9 MB\n",
      "None\n",
      "\n",
      "Number of duplicate rows: 0\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>96995</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497040</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497041</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103501</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497042</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497043</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497044</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">54</th>\n",
       "      <th>2132163</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867499</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132318</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867500</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132945</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867501</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132957</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867502</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134244</th>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>128867503</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3370464 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id  onpromotion\n",
       "store_nbr item_nbr date                              \n",
       "1         96995    2017-08-16  125497040        False\n",
       "          99197    2017-08-16  125497041        False\n",
       "          103501   2017-08-16  125497042        False\n",
       "          103520   2017-08-16  125497043        False\n",
       "          103665   2017-08-16  125497044        False\n",
       "...                                  ...          ...\n",
       "54        2132163  2017-08-31  128867499        False\n",
       "          2132318  2017-08-31  128867500        False\n",
       "          2132945  2017-08-31  128867501        False\n",
       "          2132957  2017-08-31  128867502        False\n",
       "          2134244  2017-08-31  128867503        False\n",
       "\n",
       "[3370464 rows x 2 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_df(df_test, \"Df Test\")\n",
    "\n",
    "df_test\n",
    "\n",
    "#organized by store number, starting with store 1, all items, all dates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6252b154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Df Test 2022\n",
      "(3370464, 2)\n",
      "id             int64\n",
      "onpromotion     bool\n",
      "dtype: object\n",
      "id             0\n",
      "onpromotion    0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 3370464 entries, (np.int64(1), np.int64(96995), Timestamp('2022-09-10 00:00:00')) to (np.int64(54), np.int64(2134244), Timestamp('2022-09-25 00:00:00'))\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Dtype\n",
      "---  ------       -----\n",
      " 0   id           int64\n",
      " 1   onpromotion  bool \n",
      "dtypes: bool(1), int64(1)\n",
      "memory usage: 41.9 MB\n",
      "None\n",
      "\n",
      "Number of duplicate rows: 0\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>96995</th>\n",
       "      <th>2022-09-10</th>\n",
       "      <td>125497040</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <th>2022-09-10</th>\n",
       "      <td>125497041</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103501</th>\n",
       "      <th>2022-09-10</th>\n",
       "      <td>125497042</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <th>2022-09-10</th>\n",
       "      <td>125497043</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <th>2022-09-10</th>\n",
       "      <td>125497044</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">54</th>\n",
       "      <th>2132163</th>\n",
       "      <th>2022-09-25</th>\n",
       "      <td>128867499</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132318</th>\n",
       "      <th>2022-09-25</th>\n",
       "      <td>128867500</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132945</th>\n",
       "      <th>2022-09-25</th>\n",
       "      <td>128867501</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132957</th>\n",
       "      <th>2022-09-25</th>\n",
       "      <td>128867502</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134244</th>\n",
       "      <th>2022-09-25</th>\n",
       "      <td>128867503</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3370464 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id  onpromotion\n",
       "store_nbr item_nbr date                              \n",
       "1         96995    2022-09-10  125497040        False\n",
       "          99197    2022-09-10  125497041        False\n",
       "          103501   2022-09-10  125497042        False\n",
       "          103520   2022-09-10  125497043        False\n",
       "          103665   2022-09-10  125497044        False\n",
       "...                                  ...          ...\n",
       "54        2132163  2022-09-25  128867499        False\n",
       "          2132318  2022-09-25  128867500        False\n",
       "          2132945  2022-09-25  128867501        False\n",
       "          2132957  2022-09-25  128867502        False\n",
       "          2134244  2022-09-25  128867503        False\n",
       "\n",
       "[3370464 rows x 2 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_df(df_test_2022, \"Df Test 2022\")\n",
    "\n",
    "df_test_2022\n",
    "\n",
    "#ok this could be useful, updated to year 2022, so we can see how sales patterns have changed post-pandemic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167b7865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Sample Submission\n",
      "(3370464, 2)\n",
      "id            int64\n",
      "unit_sales    int64\n",
      "dtype: object\n",
      "id            0\n",
      "unit_sales    0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3370464 entries, 0 to 3370463\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Dtype\n",
      "---  ------      -----\n",
      " 0   id          int64\n",
      " 1   unit_sales  int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 51.4 MB\n",
      "None\n",
      "\n",
      "Number of duplicate rows: 0\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>unit_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, unit_sales]\n",
       "Index: []"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_df(df_sample_submission, \"Sample Submission\")\n",
    "\n",
    "df_sample_submission[df_sample_submission['unit_sales'] > 0]\n",
    "\n",
    "#empty sales column, just a template for submission format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f612e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_uniqueness(df, name, keys):\n",
    "    total_rows = df.shape[0]\n",
    "    unique_rows = df[keys].drop_duplicates().shape[0]\n",
    "    \n",
    "    print(f\"🔎 {name}\")\n",
    "    print(f\"  Unit of analysis: {keys}\")\n",
    "    print(f\"  Total rows: {total_rows}\")\n",
    "    print(f\"  Unique rows: {unique_rows}\")\n",
    "    if total_rows == unique_rows:\n",
    "        print(\"  All rows are unique by this unit of analysis.\\n\")\n",
    "    else:\n",
    "        print(f\"{total_rows - unique_rows} duplicate rows by this unit of analysis.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d3a26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔎 Train\n",
      "  Unit of analysis: ['date', 'store_nbr', 'item_nbr']\n",
      "  Total rows: 125497040\n",
      "  Unique rows: 125497040\n",
      "  All rows are unique by this unit of analysis.\n",
      "\n",
      "🔎 Transactions\n",
      "  Unit of analysis: ['date', 'store_nbr']\n",
      "  Total rows: 83488\n",
      "  Unique rows: 83488\n",
      "  All rows are unique by this unit of analysis.\n",
      "\n",
      "🔎 Oil\n",
      "  Unit of analysis: ['date']\n",
      "  Total rows: 1218\n",
      "  Unique rows: 1218\n",
      "  All rows are unique by this unit of analysis.\n",
      "\n",
      "🔎 Holidays\n",
      "  Unit of analysis: ['date', 'description']\n",
      "  Total rows: 350\n",
      "  Unique rows: 350\n",
      "  All rows are unique by this unit of analysis.\n",
      "\n",
      "🔎 Items\n",
      "  Unit of analysis: ['family', 'class', 'perishable']\n",
      "  Total rows: 4100\n",
      "  Unique rows: 337\n",
      "3763 duplicate rows by this unit of analysis.\n",
      "\n",
      "🔎 Stores\n",
      "  Unit of analysis: ['city', 'state', 'type', 'cluster']\n",
      "  Total rows: 54\n",
      "  Unique rows: 42\n",
      "12 duplicate rows by this unit of analysis.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_uniqueness(df_train, \"Train\", [\"date\",\"store_nbr\",\"item_nbr\"])\n",
    "check_uniqueness(df_transactions, \"Transactions\", [\"date\",\"store_nbr\"])\n",
    "check_uniqueness(df_oil, \"Oil\", [\"date\"])\n",
    "check_uniqueness(df_holidays, \"Holidays\", [\"date\",\"description\"])\n",
    "check_uniqueness(df_items, \"Items\", [\"family\",\"class\",\"perishable\"])\n",
    "check_uniqueness(df_stores, \"Stores\", [\"city\",\"state\",\"type\",\"cluster\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CPSC4300",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
