{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56c4a7b5-453b-4de6-a67c-6b7582318ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16ae8d28-6b1d-4966-9381-c0dc4e6bc420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled dataset: (866805, 46)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"results/df_featured_full.parquet\"\n",
    "df = pd.read_parquet(PATH)\n",
    "\n",
    "if not np.issubdtype(df['date'].dtype, np.datetime64):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "pairs = df.groupby(['store_nbr', 'item_nbr']).agg({\n",
    "    'family': 'first',\n",
    "    'perishable': 'first',\n",
    "}).reset_index()\n",
    "\n",
    "PAIRS_PER_FAMILY = 50\n",
    "sampled_pairs = (\n",
    "    pairs.sample(frac=1, random_state=42)\n",
    "    .groupby('family')\n",
    "    .head(PAIRS_PER_FAMILY)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_sample = df.merge(\n",
    "    sampled_pairs[['store_nbr', 'item_nbr']],\n",
    "    on=['store_nbr', 'item_nbr'],\n",
    "    how='inner'\n",
    ").copy()\n",
    "\n",
    "print(f\"Sampled dataset: {df_sample.shape}\")\n",
    "del df\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2614897f-63a4-4a48-bc2f-b13c3511e77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data sorted\n"
     ]
    }
   ],
   "source": [
    "df_sample = df_sample.sort_values(['store_nbr', 'item_nbr', 'date']).reset_index(drop=True)\n",
    "\n",
    "print(\"✓ Data sorted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3baecffa-ca51-412b-9cbc-8f163003ef6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Split distribution:\n",
      "set\n",
      "train    842725\n",
      "valid     12833\n",
      "test      11247\n",
      "Name: count, dtype: int64\n",
      "             min        max\n",
      "set                        \n",
      "test  2017-07-31 2017-08-15\n",
      "train 2013-01-01 2017-07-30\n",
      "valid 2013-01-02 2017-07-30\n"
     ]
    }
   ],
   "source": [
    "max_date = df_sample['date'].max()\n",
    "test_start = max_date - pd.Timedelta(days=15)\n",
    "\n",
    "# Test set is the last 16 days\n",
    "test_mask = df_sample['date'] >= test_start\n",
    "\n",
    "# Split remaining data into train and validation\n",
    "non_test = df_sample[~test_mask].index.tolist()\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(non_test)\n",
    "\n",
    "valid_size = int(0.015 * len(non_test))\n",
    "valid_idx = non_test[:valid_size]\n",
    "train_idx = non_test[valid_size:]\n",
    "\n",
    "df_sample['set'] = 'test'\n",
    "df_sample.loc[train_idx, 'set'] = 'train'\n",
    "df_sample.loc[valid_idx, 'set'] = 'valid'\n",
    "\n",
    "print(f\"\\nSplit distribution:\")\n",
    "print(df_sample['set'].value_counts())\n",
    "print(df_sample.groupby('set')['date'].agg(['min', 'max']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ec58bcf-c703-401b-b2c5-a135b5318b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total features: 9\n"
     ]
    }
   ],
   "source": [
    "feature_cols = [\n",
    "    'store_nbr',\n",
    "    'item_nbr',\n",
    "    'onpromotion',\n",
    "    'day_of_week',\n",
    "    'day_of_month',\n",
    "    'month',\n",
    "    'perishable',\n",
    "    'is_weekend',\n",
    "    'is_holiday',\n",
    "]\n",
    "\n",
    "print(f\"\\nTotal features: {len(feature_cols)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "186dd5f9-c989-4bc1-aac4-11e66e91473f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train: (842725, 9)\n",
      "X_valid: (12833, 9)\n",
      "X_test:  (11247, 9)\n"
     ]
    }
   ],
   "source": [
    "train_df = df_sample[df_sample['set'] == 'train'].copy()\n",
    "valid_df = df_sample[df_sample['set'] == 'valid'].copy()\n",
    "test_df  = df_sample[df_sample['set'] == 'test'].copy()\n",
    "\n",
    "X_train = train_df[feature_cols].copy()\n",
    "X_valid = valid_df[feature_cols].copy()\n",
    "X_test  = test_df[feature_cols].copy()\n",
    "\n",
    "y_train = train_df['unit_sales'].values\n",
    "y_valid = valid_df['unit_sales'].values\n",
    "y_test  = test_df['unit_sales'].values\n",
    "\n",
    "# Handle categorical columns\n",
    "cat_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "bool_cols = X_train.select_dtypes(include=['bool']).columns.tolist()\n",
    "\n",
    "for X in [X_train, X_valid, X_test]:\n",
    "    for c in cat_cols:\n",
    "        X[c] = X[c].astype(str).astype('category')\n",
    "    for c in bool_cols:\n",
    "        X[c] = X[c].astype(int)\n",
    "\n",
    "print(f\"\\nX_train: {X_train.shape}\")\n",
    "print(f\"X_valid: {X_valid.shape}\")\n",
    "print(f\"X_test:  {X_test.shape}\")\n",
    "\n",
    "train_weights = 1 + train_df['perishable'].values\n",
    "valid_weights = 1 + valid_df['perishable'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ac33575-f962-40a0-adfd-7230c7aaca15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y_true, y_pred):\n",
    "    y_true = np.clip(y_true, 0, None)\n",
    "    y_pred = np.clip(y_pred, 0, None)\n",
    "    return np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    y_true = np.array(y_true, dtype=float)\n",
    "    y_pred = np.array(y_pred, dtype=float)\n",
    "    denom = np.abs(y_true) + np.abs(y_pred)\n",
    "    mask = denom != 0\n",
    "    out = np.zeros_like(denom)\n",
    "    out[mask] = 2.0 * np.abs(y_pred[mask] - y_true[mask]) / denom[mask]\n",
    "    return np.mean(out)\n",
    "\n",
    "def nwrmsle(y_true, y_pred, perishable):\n",
    "    y_true = np.clip(y_true, 0, None)\n",
    "    y_pred = np.clip(y_pred, 0, None)\n",
    "    w = 1 + (perishable == 1)\n",
    "    msle = (w * (np.log1p(y_pred) - np.log1p(y_true))**2).sum() / w.sum()\n",
    "    return np.sqrt(msle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb2ae1cf-b90e-4d79-ba47-004771f01056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating DMatrix objects...\n",
      "✓ DMatrix created\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCreating DMatrix objects...\")\n",
    "\n",
    "dtrain = xgb.DMatrix(\n",
    "    X_train, \n",
    "    label=y_train, \n",
    "    weight=train_weights,\n",
    "    enable_categorical=True\n",
    ")\n",
    "\n",
    "dvalid = xgb.DMatrix(\n",
    "    X_valid, \n",
    "    label=y_valid,\n",
    "    weight=valid_weights,\n",
    "    enable_categorical=True\n",
    ")\n",
    "\n",
    "dtest = xgb.DMatrix(\n",
    "    X_test, \n",
    "    label=y_test,\n",
    "    enable_categorical=True\n",
    ")\n",
    "\n",
    "print(\"✓ DMatrix created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "641b9aa9-cd41-4ab5-92cc-94f9d0942ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training XGBoost...\n",
      "[0]\ttrain-rmse:11.43120\tvalid-rmse:11.80289\n",
      "[53]\ttrain-rmse:0.55418\tvalid-rmse:10.60624\n",
      "\n",
      "Best iteration: 3\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'tree_method': 'hist',\n",
    "    'device': 'cuda',\n",
    "    'max_depth': 25,\n",
    "    'learning_rate': 0.3,\n",
    "    'subsample': 1.0,\n",
    "    'colsample_bytree': 1.0,\n",
    "    'min_child_weight': 1,\n",
    "    'reg_alpha': 0.0,\n",
    "    'reg_lambda': 0.0,\n",
    "    'random_state': 42,\n",
    "}\n",
    "\n",
    "print(\"\\nTraining XGBoost...\")\n",
    "\n",
    "evals = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=2000,\n",
    "    evals=evals,\n",
    "    early_stopping_rounds=50,\n",
    "    verbose_eval=100\n",
    ")\n",
    "\n",
    "print(f\"\\nBest iteration: {model.best_iteration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a34dc3e8-74ed-46c1-a7d4-196e2fc4a915",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(dtrain)\n",
    "y_valid_pred = model.predict(dvalid)\n",
    "y_test_pred  = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "534cc10c-9ee1-4b04-8d44-4d1ca796f044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "XGBOOST EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "--- TRAIN ---\n",
      "RMSLE:  0.067780\n",
      "SMAPE:  0.010723\n",
      "\n",
      "--- VALID ---\n",
      "RMSLE:  0.647197\n",
      "SMAPE:  0.577340\n",
      "\n",
      "--- TEST (last 16 days) ---\n",
      "RMSLE:  0.710084\n",
      "SMAPE:  0.610904\n",
      "\n",
      "NWRMSLE (train): 0.061692\n",
      "NWRMSLE (valid): 0.654354\n",
      "NWRMSLE (test):  0.713441\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"XGBOOST EVALUATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n--- TRAIN ---\")\n",
    "print(f\"RMSLE:  {rmsle(y_train, y_train_pred):.6f}\")\n",
    "print(f\"SMAPE:  {smape(y_train, y_train_pred):.6f}\")\n",
    "\n",
    "print(\"\\n--- VALID ---\")\n",
    "print(f\"RMSLE:  {rmsle(y_valid, y_valid_pred):.6f}\")\n",
    "print(f\"SMAPE:  {smape(y_valid, y_valid_pred):.6f}\")\n",
    "\n",
    "print(\"\\n--- TEST (last 16 days) ---\")\n",
    "print(f\"RMSLE:  {rmsle(y_test, y_test_pred):.6f}\")\n",
    "print(f\"SMAPE:  {smape(y_test, y_test_pred):.6f}\")\n",
    "\n",
    "print(f\"\\nNWRMSLE (train): {nwrmsle(y_train, y_train_pred, train_df['perishable'].values):.6f}\")\n",
    "print(f\"NWRMSLE (valid): {nwrmsle(y_valid, y_valid_pred, valid_df['perishable'].values):.6f}\")\n",
    "print(f\"NWRMSLE (test):  {nwrmsle(y_test, y_test_pred, test_df['perishable'].values):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "197aff1b-95cc-42bb-8cc0-5e15ffa8edf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FEATURE IMPORTANCE (GAIN)\n",
      "============================================================\n",
      "     feature  importance\n",
      "  perishable  984.841187\n",
      "    item_nbr  142.423126\n",
      " onpromotion   87.837112\n",
      "   store_nbr   67.609825\n",
      "day_of_month   23.381880\n",
      " day_of_week   21.657513\n",
      "  is_holiday   19.437176\n",
      "       month   13.377021\n"
     ]
    }
   ],
   "source": [
    "importance = model.get_score(importance_type='gain')\n",
    "\n",
    "fi = pd.DataFrame({\n",
    "    'feature': list(importance.keys()),\n",
    "    'importance': list(importance.values())\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FEATURE IMPORTANCE (GAIN)\")\n",
    "print(\"=\"*60)\n",
    "print(fi.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7739854-dd12-4700-9bae-0a6eccc05695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RMSLE BY DATE (TEST) - with holiday flag\n",
      "============================================================\n",
      "      date    rmsle  is_holiday\n",
      "2017-07-31 0.714330           0\n",
      "2017-08-01 0.712513           0\n",
      "2017-08-02 0.709579           0\n",
      "2017-08-03 0.682135           0\n",
      "2017-08-04 0.701710           0\n",
      "2017-08-05 0.710719           1\n",
      "2017-08-06 0.718463           0\n",
      "2017-08-07 0.743466           0\n",
      "2017-08-08 0.704992           0\n",
      "2017-08-09 0.708029           0\n",
      "2017-08-10 0.743440           1\n",
      "2017-08-11 0.691486           1\n",
      "2017-08-12 0.701753           0\n",
      "2017-08-13 0.709716           0\n",
      "2017-08-14 0.701770           0\n",
      "2017-08-15 0.705739           1\n",
      "\n",
      "Mean RMSLE: 0.709990\n",
      "Std RMSLE:  0.015719\n"
     ]
    }
   ],
   "source": [
    "test_df = test_df.copy()\n",
    "test_df['pred'] = y_test_pred\n",
    "\n",
    "date_rmsle = (\n",
    "    test_df.groupby('date')\n",
    "    .apply(lambda x: rmsle(x['unit_sales'], x['pred']))\n",
    "    .rename('rmsle')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "date_holiday_flag = df_sample[['date', 'is_holiday']].drop_duplicates()\n",
    "date_rmsle = date_rmsle.merge(date_holiday_flag, on='date', how='left')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RMSLE BY DATE (TEST) - with holiday flag\")\n",
    "print(\"=\"*60)\n",
    "print(date_rmsle.to_string(index=False))\n",
    "print(f\"\\nMean RMSLE: {date_rmsle['rmsle'].mean():.6f}\")\n",
    "print(f\"Std RMSLE:  {date_rmsle['rmsle'].std():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2153a79e-5645-4f31-988e-b5b93eb53e06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================================================\n",
      "FIRST 3 PREDICTION DAYS ANALYSIS - 3 RANDOM ITEMS\n",
      "==========================================================================================\n",
      "Selected Items: [2042941 1695836 1369972]\n",
      "Dates: ['2017-07-31', '2017-08-01', '2017-08-02']\n",
      "Total records: 7\n",
      "\n",
      "==========================================================================================\n",
      "PREDICTIONS BY ITEM, DATE, AND STORE\n",
      "==========================================================================================\n",
      "      date  store_nbr  item_nbr              family  is_holiday  true_sales  predicted_sales  error  abs_error  pct_error\n",
      "2017-08-01          2   1369972 HOME AND KITCHEN II           0       1.000         1.340000   0.34       0.34      17.14\n",
      "2017-07-31         22   1695836             PRODUCE           0       2.359         5.340000   2.98       2.98      88.72\n",
      "2017-08-01         22   1695836             PRODUCE           0       5.634         2.700000  -2.93       2.93     -44.21\n",
      "2017-08-02         22   1695836             PRODUCE           0       2.000         0.870000  -1.13       1.13     -37.80\n",
      "2017-07-31          5   2042941           BEVERAGES           0      45.000        78.959999  33.96      33.96      73.82\n",
      "2017-08-01          5   2042941           BEVERAGES           0      59.000        93.989998  34.99      34.99      58.31\n",
      "2017-08-02          5   2042941           BEVERAGES           0      48.000        65.010002  17.01      17.01      34.71\n",
      "\n",
      "==========================================================================================\n",
      "SUMMARY BY DATE (with holiday flag)\n",
      "==========================================================================================\n",
      "                       n_records  total_true_sales  avg_true_sales  \\\n",
      "date       is_holiday                                                \n",
      "2017-07-31 0                   2             47.36           23.68   \n",
      "2017-08-01 0                   3             65.63           21.88   \n",
      "2017-08-02 0                   2             50.00           25.00   \n",
      "\n",
      "                       total_predicted  avg_predicted    MAE  total_abs_error  \n",
      "date       is_holiday                                                          \n",
      "2017-07-31 0                 84.300003      42.150002  18.47            36.94  \n",
      "2017-08-01 0                 98.029999      32.680000  12.75            38.26  \n",
      "2017-08-02 0                 65.870003      32.939999   9.07            18.14  \n",
      "\n",
      "==========================================================================================\n",
      "SUMMARY BY ITEM\n",
      "==========================================================================================\n",
      "          n_records  total_true_sales  avg_true_sales  total_predicted  avg_predicted    MAE               family\n",
      "item_nbr                                                                                                         \n",
      "1369972           1              1.00            1.00         1.340000           1.34   0.34  HOME AND KITCHEN II\n",
      "1695836           3              9.99            3.33         8.910000           2.97   2.35              PRODUCE\n",
      "2042941           3            152.00           50.67       237.949997          79.32  28.65            BEVERAGES\n",
      "\n",
      "==========================================================================================\n",
      "SUMMARY BY ITEM AND DATE (with holiday flag)\n",
      "==========================================================================================\n",
      "                                n_stores  total_true_sales  avg_true_sales  avg_predicted    MAE\n",
      "item_nbr date       is_holiday                                                                  \n",
      "1369972  2017-08-01 0                  1              1.00            1.00       1.340000   0.34\n",
      "1695836  2017-07-31 0                  1              2.36            2.36       5.340000   2.98\n",
      "         2017-08-01 0                  1              5.63            5.63       2.700000   2.93\n",
      "         2017-08-02 0                  1              2.00            2.00       0.870000   1.13\n",
      "2042941  2017-07-31 0                  1             45.00           45.00      78.959999  33.96\n",
      "         2017-08-01 0                  1             59.00           59.00      93.989998  34.99\n",
      "         2017-08-02 0                  1             48.00           48.00      65.010002  17.01\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# FIRST 3 DAYS PREDICTION ANALYSIS - 3 RANDOM ITEMS\n",
    "# ============================================================\n",
    "\n",
    "# Select 3 random items\n",
    "np.random.seed(42)\n",
    "all_items = test_df['item_nbr'].unique()\n",
    "TARGET_ITEMS = np.random.choice(all_items, size=3, replace=False)\n",
    "\n",
    "first_3_dates = sorted(test_df['date'].unique())[:3]\n",
    "print(f\"\\n\" + \"=\"*90)\n",
    "print(f\"FIRST 3 PREDICTION DAYS ANALYSIS - 3 RANDOM ITEMS\")\n",
    "print(\"=\"*90)\n",
    "print(f\"Selected Items: {TARGET_ITEMS}\")\n",
    "print(f\"Dates: {[str(d.date()) for d in first_3_dates]}\")\n",
    "\n",
    "# Filter for these dates and items\n",
    "first_3_days_df = test_df[\n",
    "    (test_df['date'].isin(first_3_dates)) & \n",
    "    (test_df['item_nbr'].isin(TARGET_ITEMS))\n",
    "].copy()\n",
    "\n",
    "print(f\"Total records: {len(first_3_days_df)}\")\n",
    "\n",
    "# Calculate errors\n",
    "first_3_days_df['error'] = first_3_days_df['pred'] - first_3_days_df['unit_sales']\n",
    "first_3_days_df['abs_error'] = np.abs(first_3_days_df['error'])\n",
    "first_3_days_df['pct_error'] = (first_3_days_df['error'] / (first_3_days_df['unit_sales'] + 1)) * 100\n",
    "\n",
    "# Select columns including is_holiday\n",
    "result_df = first_3_days_df[[\n",
    "    'date', 'store_nbr', 'item_nbr', 'family', 'is_holiday',\n",
    "    'unit_sales', 'pred', 'error', 'abs_error', 'pct_error'\n",
    "]].copy()\n",
    "\n",
    "result_df = result_df.rename(columns={\n",
    "    'unit_sales': 'true_sales',\n",
    "    'pred': 'predicted_sales'\n",
    "})\n",
    "\n",
    "# Round for readability\n",
    "result_df['predicted_sales'] = result_df['predicted_sales'].round(2)\n",
    "result_df['error'] = result_df['error'].round(2)\n",
    "result_df['abs_error'] = result_df['abs_error'].round(2)\n",
    "result_df['pct_error'] = result_df['pct_error'].round(2)\n",
    "\n",
    "result_df = result_df.sort_values(['item_nbr', 'date', 'store_nbr']).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"PREDICTIONS BY ITEM, DATE, AND STORE\")\n",
    "print(\"=\"*90)\n",
    "print(result_df.to_string(index=False))\n",
    "\n",
    "# Summary by date with holiday flag\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"SUMMARY BY DATE (with holiday flag)\")\n",
    "print(\"=\"*90)\n",
    "date_summary = first_3_days_df.groupby(['date', 'is_holiday']).agg({\n",
    "    'unit_sales': ['count', 'sum', 'mean'],\n",
    "    'pred': ['sum', 'mean'],\n",
    "    'abs_error': ['mean', 'sum']\n",
    "}).round(2)\n",
    "date_summary.columns = ['n_records', 'total_true_sales', 'avg_true_sales', \n",
    "                        'total_predicted', 'avg_predicted', 'MAE', 'total_abs_error']\n",
    "print(date_summary)\n",
    "\n",
    "# Summary by item\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"SUMMARY BY ITEM\")\n",
    "print(\"=\"*90)\n",
    "item_summary = first_3_days_df.groupby('item_nbr').agg({\n",
    "    'unit_sales': ['count', 'sum', 'mean'],\n",
    "    'pred': ['sum', 'mean'],\n",
    "    'abs_error': 'mean',\n",
    "    'family': 'first'\n",
    "}).round(2)\n",
    "item_summary.columns = ['n_records', 'total_true_sales', 'avg_true_sales', \n",
    "                        'total_predicted', 'avg_predicted', 'MAE', 'family']\n",
    "print(item_summary.to_string())\n",
    "\n",
    "# Summary by item and date\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"SUMMARY BY ITEM AND DATE (with holiday flag)\")\n",
    "print(\"=\"*90)\n",
    "item_date_summary = first_3_days_df.groupby(['item_nbr', 'date', 'is_holiday']).agg({\n",
    "    'unit_sales': ['count', 'sum', 'mean'],\n",
    "    'pred': ['mean'],\n",
    "    'abs_error': 'mean'\n",
    "}).round(2)\n",
    "item_date_summary.columns = ['n_stores', 'total_true_sales', 'avg_true_sales', \n",
    "                              'avg_predicted', 'MAE']\n",
    "print(item_date_summary.to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
