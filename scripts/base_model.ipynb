{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56c4a7b5-453b-4de6-a67c-6b7582318ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16ae8d28-6b1d-4966-9381-c0dc4e6bc420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled dataset: (866805, 46)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"results/df_featured_full.parquet\"\n",
    "df = pd.read_parquet(PATH)\n",
    "\n",
    "if not np.issubdtype(df['date'].dtype, np.datetime64):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "pairs = df.groupby(['store_nbr', 'item_nbr']).agg({\n",
    "    'family': 'first',\n",
    "    'perishable': 'first',\n",
    "}).reset_index()\n",
    "\n",
    "PAIRS_PER_FAMILY = 50\n",
    "sampled_pairs = (\n",
    "    pairs.sample(frac=1, random_state=42)\n",
    "    .groupby('family')\n",
    "    .head(PAIRS_PER_FAMILY)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_sample = df.merge(\n",
    "    sampled_pairs[['store_nbr', 'item_nbr']],\n",
    "    on=['store_nbr', 'item_nbr'],\n",
    "    how='inner'\n",
    ").copy()\n",
    "\n",
    "print(f\"Sampled dataset: {df_sample.shape}\")\n",
    "del df\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2614897f-63a4-4a48-bc2f-b13c3511e77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data sorted\n"
     ]
    }
   ],
   "source": [
    "df_sample = df_sample.sort_values(['store_nbr', 'item_nbr', 'date']).reset_index(drop=True)\n",
    "\n",
    "print(\"✓ Data sorted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3baecffa-ca51-412b-9cbc-8f163003ef6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Split distribution:\n",
      "set\n",
      "train    842725\n",
      "valid     12833\n",
      "test      11247\n",
      "Name: count, dtype: int64\n",
      "             min        max\n",
      "set                        \n",
      "test  2017-07-31 2017-08-15\n",
      "train 2013-01-01 2017-07-30\n",
      "valid 2013-01-02 2017-07-30\n"
     ]
    }
   ],
   "source": [
    "max_date = df_sample['date'].max()\n",
    "test_start = max_date - pd.Timedelta(days=15)\n",
    "\n",
    "# Test set is the last 16 days\n",
    "test_mask = df_sample['date'] >= test_start\n",
    "\n",
    "# Split remaining data into train and validation\n",
    "non_test = df_sample[~test_mask].index.tolist()\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(non_test)\n",
    "\n",
    "valid_size = int(0.015 * len(non_test))\n",
    "valid_idx = non_test[:valid_size]\n",
    "train_idx = non_test[valid_size:]\n",
    "\n",
    "df_sample['set'] = 'test'\n",
    "df_sample.loc[train_idx, 'set'] = 'train'\n",
    "df_sample.loc[valid_idx, 'set'] = 'valid'\n",
    "\n",
    "print(f\"\\nSplit distribution:\")\n",
    "print(df_sample['set'].value_counts())\n",
    "print(df_sample.groupby('set')['date'].agg(['min', 'max']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ec58bcf-c703-401b-b2c5-a135b5318b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total features: 9\n"
     ]
    }
   ],
   "source": [
    "feature_cols = [\n",
    "    'store_nbr',\n",
    "    'item_nbr',\n",
    "    'onpromotion',\n",
    "    'day_of_week',\n",
    "    'day_of_month',\n",
    "    'month',\n",
    "    'perishable',\n",
    "    'is_weekend',\n",
    "    'is_holiday',\n",
    "]\n",
    "\n",
    "print(f\"\\nTotal features: {len(feature_cols)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "186dd5f9-c989-4bc1-aac4-11e66e91473f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train: (842725, 9)\n",
      "X_valid: (12833, 9)\n",
      "X_test:  (11247, 9)\n"
     ]
    }
   ],
   "source": [
    "train_df = df_sample[df_sample['set'] == 'train'].copy()\n",
    "valid_df = df_sample[df_sample['set'] == 'valid'].copy()\n",
    "test_df  = df_sample[df_sample['set'] == 'test'].copy()\n",
    "\n",
    "X_train = train_df[feature_cols].copy()\n",
    "X_valid = valid_df[feature_cols].copy()\n",
    "X_test  = test_df[feature_cols].copy()\n",
    "\n",
    "y_train = train_df['unit_sales'].values\n",
    "y_valid = valid_df['unit_sales'].values\n",
    "y_test  = test_df['unit_sales'].values\n",
    "\n",
    "# Handle categorical columns\n",
    "cat_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "bool_cols = X_train.select_dtypes(include=['bool']).columns.tolist()\n",
    "\n",
    "for X in [X_train, X_valid, X_test]:\n",
    "    for c in cat_cols:\n",
    "        X[c] = X[c].astype(str).astype('category')\n",
    "    for c in bool_cols:\n",
    "        X[c] = X[c].astype(int)\n",
    "\n",
    "print(f\"\\nX_train: {X_train.shape}\")\n",
    "print(f\"X_valid: {X_valid.shape}\")\n",
    "print(f\"X_test:  {X_test.shape}\")\n",
    "\n",
    "train_weights = 1 + train_df['perishable'].values\n",
    "valid_weights = 1 + valid_df['perishable'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ac33575-f962-40a0-adfd-7230c7aaca15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y_true, y_pred):\n",
    "    y_true = np.clip(y_true, 0, None)\n",
    "    y_pred = np.clip(y_pred, 0, None)\n",
    "    return np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    y_true = np.array(y_true, dtype=float)\n",
    "    y_pred = np.array(y_pred, dtype=float)\n",
    "    denom = np.abs(y_true) + np.abs(y_pred)\n",
    "    mask = denom != 0\n",
    "    out = np.zeros_like(denom)\n",
    "    out[mask] = 2.0 * np.abs(y_pred[mask] - y_true[mask]) / denom[mask]\n",
    "    return np.mean(out)\n",
    "\n",
    "def nwrmsle(y_true, y_pred, perishable):\n",
    "    y_true = np.clip(y_true, 0, None)\n",
    "    y_pred = np.clip(y_pred, 0, None)\n",
    "    w = 1 + (perishable == 1)\n",
    "    msle = (w * (np.log1p(y_pred) - np.log1p(y_true))**2).sum() / w.sum()\n",
    "    return np.sqrt(msle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb2ae1cf-b90e-4d79-ba47-004771f01056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating DMatrix objects...\n",
      "✓ DMatrix created\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCreating DMatrix objects...\")\n",
    "\n",
    "dtrain = xgb.DMatrix(\n",
    "    X_train, \n",
    "    label=y_train, \n",
    "    weight=train_weights,\n",
    "    enable_categorical=True\n",
    ")\n",
    "\n",
    "dvalid = xgb.DMatrix(\n",
    "    X_valid, \n",
    "    label=y_valid,\n",
    "    weight=valid_weights,\n",
    "    enable_categorical=True\n",
    ")\n",
    "\n",
    "dtest = xgb.DMatrix(\n",
    "    X_test, \n",
    "    label=y_test,\n",
    "    enable_categorical=True\n",
    ")\n",
    "\n",
    "print(\"✓ DMatrix created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "641b9aa9-cd41-4ab5-92cc-94f9d0942ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training XGBoost...\n",
      "[0]\ttrain-rmse:11.43120\tvalid-rmse:11.80289\n",
      "[53]\ttrain-rmse:0.55418\tvalid-rmse:10.60624\n",
      "\n",
      "Best iteration: 3\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'tree_method': 'hist',\n",
    "    'device': 'cuda',\n",
    "    'max_depth': 25,\n",
    "    'learning_rate': 0.3,\n",
    "    'subsample': 1.0,\n",
    "    'colsample_bytree': 1.0,\n",
    "    'min_child_weight': 1,\n",
    "    'reg_alpha': 0.0,\n",
    "    'reg_lambda': 0.0,\n",
    "    'random_state': 42,\n",
    "}\n",
    "\n",
    "print(\"\\nTraining XGBoost...\")\n",
    "\n",
    "evals = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=2000,\n",
    "    evals=evals,\n",
    "    early_stopping_rounds=50,\n",
    "    verbose_eval=100\n",
    ")\n",
    "\n",
    "print(f\"\\nBest iteration: {model.best_iteration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a34dc3e8-74ed-46c1-a7d4-196e2fc4a915",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(dtrain)\n",
    "y_valid_pred = model.predict(dvalid)\n",
    "y_test_pred  = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "534cc10c-9ee1-4b04-8d44-4d1ca796f044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "XGBOOST EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "--- TRAIN ---\n",
      "RMSLE:  0.067780\n",
      "SMAPE:  0.010723\n",
      "\n",
      "--- VALID ---\n",
      "RMSLE:  0.647197\n",
      "SMAPE:  0.577340\n",
      "\n",
      "--- TEST (last 16 days) ---\n",
      "RMSLE:  0.710084\n",
      "SMAPE:  0.610904\n",
      "\n",
      "NWRMSLE (train): 0.061692\n",
      "NWRMSLE (valid): 0.654354\n",
      "NWRMSLE (test):  0.713441\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"XGBOOST EVALUATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n--- TRAIN ---\")\n",
    "print(f\"RMSLE:  {rmsle(y_train, y_train_pred):.6f}\")\n",
    "print(f\"SMAPE:  {smape(y_train, y_train_pred):.6f}\")\n",
    "\n",
    "print(\"\\n--- VALID ---\")\n",
    "print(f\"RMSLE:  {rmsle(y_valid, y_valid_pred):.6f}\")\n",
    "print(f\"SMAPE:  {smape(y_valid, y_valid_pred):.6f}\")\n",
    "\n",
    "print(\"\\n--- TEST (last 16 days) ---\")\n",
    "print(f\"RMSLE:  {rmsle(y_test, y_test_pred):.6f}\")\n",
    "print(f\"SMAPE:  {smape(y_test, y_test_pred):.6f}\")\n",
    "\n",
    "print(f\"\\nNWRMSLE (train): {nwrmsle(y_train, y_train_pred, train_df['perishable'].values):.6f}\")\n",
    "print(f\"NWRMSLE (valid): {nwrmsle(y_valid, y_valid_pred, valid_df['perishable'].values):.6f}\")\n",
    "print(f\"NWRMSLE (test):  {nwrmsle(y_test, y_test_pred, test_df['perishable'].values):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "197aff1b-95cc-42bb-8cc0-5e15ffa8edf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FEATURE IMPORTANCE (GAIN)\n",
      "============================================================\n",
      "     feature  importance\n",
      "  perishable  984.841187\n",
      "    item_nbr  142.423126\n",
      " onpromotion   87.837112\n",
      "   store_nbr   67.609825\n",
      "day_of_month   23.381880\n",
      " day_of_week   21.657513\n",
      "  is_holiday   19.437176\n",
      "       month   13.377021\n"
     ]
    }
   ],
   "source": [
    "importance = model.get_score(importance_type='gain')\n",
    "\n",
    "fi = pd.DataFrame({\n",
    "    'feature': list(importance.keys()),\n",
    "    'importance': list(importance.values())\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FEATURE IMPORTANCE (GAIN)\")\n",
    "print(\"=\"*60)\n",
    "print(fi.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7739854-dd12-4700-9bae-0a6eccc05695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RMSLE BY DATE (TEST) - with holiday flag\n",
      "============================================================\n",
      "      date    rmsle  is_holiday\n",
      "2017-07-31 0.714330           0\n",
      "2017-08-01 0.712513           0\n",
      "2017-08-02 0.709579           0\n",
      "2017-08-03 0.682135           0\n",
      "2017-08-04 0.701710           0\n",
      "2017-08-05 0.710719           1\n",
      "2017-08-06 0.718463           0\n",
      "2017-08-07 0.743466           0\n",
      "2017-08-08 0.704992           0\n",
      "2017-08-09 0.708029           0\n",
      "2017-08-10 0.743440           1\n",
      "2017-08-11 0.691486           1\n",
      "2017-08-12 0.701753           0\n",
      "2017-08-13 0.709716           0\n",
      "2017-08-14 0.701770           0\n",
      "2017-08-15 0.705739           1\n",
      "\n",
      "Mean RMSLE: 0.709990\n",
      "Std RMSLE:  0.015719\n"
     ]
    }
   ],
   "source": [
    "test_df = test_df.copy()\n",
    "test_df['pred'] = y_test_pred\n",
    "\n",
    "date_rmsle = (\n",
    "    test_df.groupby('date')\n",
    "    .apply(lambda x: rmsle(x['unit_sales'], x['pred']))\n",
    "    .rename('rmsle')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "date_holiday_flag = df_sample[['date', 'is_holiday']].drop_duplicates()\n",
    "date_rmsle = date_rmsle.merge(date_holiday_flag, on='date', how='left')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RMSLE BY DATE (TEST) - with holiday flag\")\n",
    "print(\"=\"*60)\n",
    "print(date_rmsle.to_string(index=False))\n",
    "print(f\"\\nMean RMSLE: {date_rmsle['rmsle'].mean():.6f}\")\n",
    "print(f\"Std RMSLE:  {date_rmsle['rmsle'].std():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2153a79e-5645-4f31-988e-b5b93eb53e06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "RANDOM 20 ITEMS - MODEL COMPARISON\n",
      "==========================================================================================\n",
      "Selected Items: [167437, 322094, 507958, 759894, 852937, 956013, 1085246, 1229440, 1239808, 1370542, 1373944, 1430083, 1456910, 1459058, 1584348, 1900715, 1931079, 2046297, 2046298, 2053751]\n",
      "Total records: 274\n",
      "\n",
      "==========================================================================================\n",
      "RMSLE BY ITEM\n",
      "==========================================================================================\n",
      "          n_records  avg_true_sales  avg_predicted      MAE   RMSLE               family\n",
      "item_nbr                                                                                \n",
      "507958           23         13.2666       7.073000  11.6019  1.1607              POULTRY\n",
      "2053751          16          6.3125       4.438100   5.8738  1.1405            BEVERAGES\n",
      "1239808          14          7.9286      11.586800   6.7829  0.8078                DAIRY\n",
      "759894           28          3.0714       4.925900   3.1916  0.7913        PERSONAL CARE\n",
      "1085246          16         11.1907       7.412000   5.6248  0.7012                MEATS\n",
      "167437            6          3.3333       4.288700   3.0898  0.6837           GROCERY II\n",
      "1430083           5          1.6000       2.942900   1.7920  0.6723   HOME AND KITCHEN I\n",
      "1373944          20          2.0000       2.612500   1.8466  0.6375  HOME AND KITCHEN II\n",
      "956013           16         15.5625      20.061399  10.1513  0.6369            GROCERY I\n",
      "1456910          10          3.1000       2.400300   1.8998  0.5904            HOME CARE\n",
      "1459058          16         12.3750      12.599700   5.4789  0.5664            GROCERY I\n",
      "2046298           8          1.3750       2.190100   1.3152  0.5550      LAWN AND GARDEN\n",
      "2046297           8          2.1250       2.551900   1.1771  0.4875      LAWN AND GARDEN\n",
      "852937           21          2.1429       2.890400   1.3941  0.4778         FROZEN FOODS\n",
      "1370542           5          4.4000       5.810100   1.8016  0.4248   HOME AND KITCHEN I\n",
      "322094           15          2.2667       2.223400   0.9707  0.4134             CLEANING\n",
      "1900715           8          2.0000       1.777400   0.8057  0.3444        PERSONAL CARE\n",
      "1229440           4          1.0000       1.611700   0.6117  0.2933        PERSONAL CARE\n",
      "1931079          32          1.4062       1.317500   0.4879  0.2680         PET SUPPLIES\n",
      "1584348           3          1.0000       1.126500   0.2364  0.1440           LADIESWEAR\n",
      "\n",
      "==========================================================================================\n",
      "OVERALL METRICS (20 ITEMS SAMPLE)\n",
      "==========================================================================================\n",
      "RMSLE:       0.691225\n",
      "MAE:         3.8929\n",
      "Avg True:    5.5664\n",
      "Avg Pred:    5.5436\n",
      "\n",
      "==========================================================================================\n",
      "SAMPLE PREDICTIONS (50 rows)\n",
      "==========================================================================================\n",
      "      date  store_nbr  item_nbr        family  dow  promo  is_holiday  true_sales  predicted  abs_error\n",
      "2017-08-09         41    167437    GROCERY II    2      0           0      10.000   4.770000       5.23\n",
      "2017-08-10         41    167437    GROCERY II    3      0           1       3.000   1.830000       1.17\n",
      "2017-08-11         41    167437    GROCERY II    4      0           1       1.000   1.260000       0.26\n",
      "2017-08-12         41    167437    GROCERY II    5      0           0       2.000   7.050000       5.05\n",
      "2017-08-13         41    167437    GROCERY II    6      0           0       3.000   6.880000       3.88\n",
      "2017-08-15         41    167437    GROCERY II    1      0           1       1.000   3.940000       2.94\n",
      "2017-07-31          4    322094      CLEANING    0      0           0       1.000   4.020000       3.02\n",
      "2017-08-01          4    322094      CLEANING    1      0           0       5.000   4.850000       0.15\n",
      "2017-08-02          4    322094      CLEANING    2      0           0       3.000   4.070000       1.07\n",
      "2017-08-03          4    322094      CLEANING    3      0           0       3.000   1.070000       1.93\n",
      "2017-08-04          4    322094      CLEANING    4      0           0       2.000   1.650000       0.35\n",
      "2017-08-05          4    322094      CLEANING    5      0           1       2.000   2.150000       0.15\n",
      "2017-08-06          4    322094      CLEANING    6      0           0       3.000   1.430000       1.57\n",
      "2017-08-07          4    322094      CLEANING    0      0           0       2.000   2.080000       0.08\n",
      "2017-08-08          4    322094      CLEANING    1      0           0       2.000   1.380000       0.62\n",
      "2017-08-09          4    322094      CLEANING    2      0           0       1.000   1.880000       0.88\n",
      "2017-08-11          4    322094      CLEANING    4      0           1       3.000   3.570000       0.57\n",
      "2017-08-12          4    322094      CLEANING    5      0           0       3.000   1.220000       1.78\n",
      "2017-08-13          4    322094      CLEANING    6      0           0       2.000   0.800000       1.20\n",
      "2017-08-14          4    322094      CLEANING    0      0           0       1.000   1.360000       0.36\n",
      "2017-08-15          4    322094      CLEANING    1      0           1       1.000   1.830000       0.83\n",
      "2017-07-31         21    507958       POULTRY    0      0           0       5.778   9.580000       3.80\n",
      "2017-08-01         21    507958       POULTRY    1      0           0       3.981  31.889999      27.91\n",
      "2017-08-02         49    507958       POULTRY    2      0           0       9.485   3.320000       6.17\n",
      "2017-08-03         49    507958       POULTRY    3      0           0       2.278   7.140000       4.86\n",
      "2017-08-04         49    507958       POULTRY    4      1           0       2.417   3.640000       1.23\n",
      "2017-08-05         49    507958       POULTRY    5      0           1       4.228  17.549999      13.32\n",
      "2017-08-06         21    507958       POULTRY    6      0           0       2.861   6.640000       3.78\n",
      "2017-08-06         49    507958       POULTRY    6      0           0      14.224   1.820000      12.40\n",
      "2017-08-07         49    507958       POULTRY    0      0           0      55.622  13.940000      41.68\n",
      "2017-08-08         49    507958       POULTRY    1      0           0      27.768   3.390000      24.38\n",
      "2017-08-09         21    507958       POULTRY    2      0           0       2.961   3.390000       0.43\n",
      "2017-08-09         49    507958       POULTRY    2      0           0      30.062   2.840000      27.22\n",
      "2017-08-10         21    507958       POULTRY    3      0           1       7.776   3.780000       4.00\n",
      "2017-08-10         49    507958       POULTRY    3      0           1      15.745   5.750000      10.00\n",
      "2017-08-11         21    507958       POULTRY    4      1           1       1.880   3.700000       1.82\n",
      "2017-08-11         49    507958       POULTRY    4      1           1      28.015   7.250000      20.77\n",
      "2017-08-12         21    507958       POULTRY    5      0           0      13.931   6.390000       7.54\n",
      "2017-08-12         49    507958       POULTRY    5      0           0      17.409   4.580000      12.82\n",
      "2017-08-13         21    507958       POULTRY    6      0           0      20.313   4.640000      15.68\n",
      "2017-08-13         49    507958       POULTRY    6      0           0      12.571   1.800000      10.77\n",
      "2017-08-14         21    507958       POULTRY    0      0           0       5.873   8.990000       3.12\n",
      "2017-08-14         49    507958       POULTRY    0      1           0      14.868   3.650000      11.22\n",
      "2017-08-15         49    507958       POULTRY    1      0           1       5.085   7.010000       1.92\n",
      "2017-07-31         35    759894 PERSONAL CARE    0      0           0       2.000   3.100000       1.10\n",
      "2017-07-31         47    759894 PERSONAL CARE    0      0           0       5.000   4.200000       0.80\n",
      "2017-08-01         35    759894 PERSONAL CARE    1      0           0       2.000   2.900000       0.90\n",
      "2017-08-01         47    759894 PERSONAL CARE    1      0           0       3.000   7.220000       4.22\n",
      "2017-08-02         47    759894 PERSONAL CARE    2      0           0       4.000   6.520000       2.52\n",
      "2017-08-03         47    759894 PERSONAL CARE    3      0           0       4.000   8.110000       4.11\n",
      "\n",
      "==========================================================================================\n",
      "RMSLE BY FAMILY (within 20 items sample)\n",
      "==========================================================================================\n",
      "                     n_items  n_records  avg_true  avg_pred      MAE   RMSLE\n",
      "family                                                                      \n",
      "POULTRY                  1.0       23.0   13.2666    7.0730  11.6019  1.1607\n",
      "BEVERAGES                1.0       16.0    6.3125    4.4381   5.8738  1.1405\n",
      "DAIRY                    1.0       14.0    7.9286   11.5868   6.7829  0.8078\n",
      "MEATS                    1.0       16.0   11.1907    7.4120   5.6248  0.7012\n",
      "PERSONAL CARE            3.0       40.0    2.6500    3.9648   2.4565  0.6860\n",
      "GROCERY II               1.0        6.0    3.3333    4.2887   3.0898  0.6837\n",
      "HOME AND KITCHEN II      1.0       20.0    2.0000    2.6125   1.8466  0.6375\n",
      "GROCERY I                2.0       32.0   13.9688   16.3305   7.8151  0.6027\n",
      "HOME CARE                1.0       10.0    3.1000    2.4003   1.8998  0.5904\n",
      "HOME AND KITCHEN I       2.0       10.0    3.0000    4.3765   1.7968  0.5623\n",
      "LAWN AND GARDEN          2.0       16.0    1.7500    2.3710   1.2461  0.5223\n",
      "FROZEN FOODS             1.0       21.0    2.1429    2.8904   1.3941  0.4778\n",
      "CLEANING                 1.0       15.0    2.2667    2.2234   0.9707  0.4134\n",
      "PET SUPPLIES             1.0       32.0    1.4062    1.3175   0.4879  0.2680\n",
      "LADIESWEAR               1.0        3.0    1.0000    1.1265   0.2364  0.1440\n",
      "\n",
      "==========================================================================================\n",
      "RMSLE BY PROMOTION STATUS (within 20 items sample)\n",
      "==========================================================================================\n",
      "          n_records  avg_true  avg_pred     MAE   RMSLE\n",
      "No Promo      263.0    5.4316    5.5129  3.7464  0.6747\n",
      "On Promo       11.0    8.7881    6.2776  7.3950  1.0093\n",
      "\n",
      "==========================================================================================\n",
      "RMSLE BY DAY OF WEEK (within 20 items sample)\n",
      "==========================================================================================\n",
      "             n_records  avg_true  avg_pred     MAE   RMSLE\n",
      "day_of_week                                               \n",
      "Monday            49.0    5.6336    5.4409  3.8453  0.6514\n",
      "Tuesday           49.0    5.0570    4.9762  3.0705  0.6308\n",
      "Wednesday         36.0    5.7068    4.7407  3.4983  0.7094\n",
      "Thursday          29.0    4.8205    4.9325  3.9806  0.8217\n",
      "Friday            38.0    5.4158    4.5370  3.2302  0.5627\n",
      "Saturday          36.0    5.2053    7.1151  4.8768  0.7582\n",
      "Sunday            37.0    7.1057    7.1959  5.0836  0.7389\n",
      "\n",
      "==========================================================================================\n",
      "COMPARISON\n",
      "==========================================================================================\n",
      "\n",
      "MODEL: XGboost Final\n",
      "------------------------\n",
      "Overall RMSLE (20 items): 0.691225\n",
      "Overall MAE (20 items):   3.8929\n",
      "\n",
      "Best Item RMSLE:  0.1440 (item 1584348)\n",
      "Worst Item RMSLE: 1.1607 (item 507958)\n",
      "Std of Item RMSLE: 0.2599\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RANDOM SAMPLE OF 20 ITEMS - FOR MODEL COMPARISON\n",
    "np.random.seed(99)\n",
    "all_items = test_df['item_nbr'].unique()\n",
    "SAMPLE_ITEMS = np.random.choice(all_items, size=20, replace=False)\n",
    "\n",
    "print(\"=\"*90)\n",
    "print(\"RANDOM 20 ITEMS - MODEL COMPARISON\")\n",
    "print(\"=\"*90)\n",
    "print(f\"Selected Items: {sorted(SAMPLE_ITEMS)}\")\n",
    "\n",
    "# Filter for sample items (all test dates)\n",
    "sample_df = test_df[test_df['item_nbr'].isin(SAMPLE_ITEMS)].copy()\n",
    "\n",
    "print(f\"Total records: {len(sample_df)}\")\n",
    "\n",
    "# Calculate errors\n",
    "sample_df['error'] = sample_df['pred'] - sample_df['unit_sales']\n",
    "sample_df['abs_error'] = np.abs(sample_df['error'])\n",
    "\n",
    "# RMSLE BY ITEM\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"RMSLE BY ITEM\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "item_metrics = sample_df.groupby('item_nbr').apply(\n",
    "    lambda x: pd.Series({\n",
    "        'n_records': len(x),\n",
    "        'avg_true_sales': x['unit_sales'].mean(),\n",
    "        'avg_predicted': x['pred'].mean(),\n",
    "        'MAE': x['abs_error'].mean(),\n",
    "        'RMSLE': rmsle(x['unit_sales'], x['pred']),\n",
    "        'family': x['family'].iloc[0]\n",
    "    })\n",
    ").round(4)\n",
    "\n",
    "item_metrics = item_metrics.sort_values('RMSLE', ascending=False)\n",
    "print(item_metrics.to_string())\n",
    "\n",
    "# OVERALL METRICS FOR THESE 20 ITEMS\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"OVERALL METRICS (20 ITEMS SAMPLE)\")\n",
    "print(\"=\"*90)\n",
    "print(f\"RMSLE:       {rmsle(sample_df['unit_sales'], sample_df['pred']):.6f}\")\n",
    "print(f\"MAE:         {sample_df['abs_error'].mean():.4f}\")\n",
    "print(f\"Avg True:    {sample_df['unit_sales'].mean():.4f}\")\n",
    "print(f\"Avg Pred:    {sample_df['pred'].mean():.4f}\")\n",
    "\n",
    "# SAMPLE PREDICTIONS (first 50 rows)\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"SAMPLE PREDICTIONS (50 rows)\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "sample_preview = sample_df[[\n",
    "    'date', 'store_nbr', 'item_nbr', 'family', 'day_of_week', 'onpromotion', 'is_holiday',\n",
    "    'unit_sales', 'pred', 'abs_error'\n",
    "]].copy()\n",
    "\n",
    "sample_preview = sample_preview.rename(columns={\n",
    "    'unit_sales': 'true_sales',\n",
    "    'pred': 'predicted',\n",
    "    'day_of_week': 'dow',\n",
    "    'onpromotion': 'promo'\n",
    "})\n",
    "\n",
    "sample_preview['predicted'] = sample_preview['predicted'].round(2)\n",
    "sample_preview['abs_error'] = sample_preview['abs_error'].round(2)\n",
    "sample_preview = sample_preview.sort_values(['item_nbr', 'date', 'store_nbr'])\n",
    "\n",
    "print(sample_preview.head(50).to_string(index=False))\n",
    "\n",
    "# METRICS BY FAMILY\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"RMSLE BY FAMILY (within 20 items sample)\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "family_metrics = sample_df.groupby('family').apply(\n",
    "    lambda x: pd.Series({\n",
    "        'n_items': x['item_nbr'].nunique(),\n",
    "        'n_records': len(x),\n",
    "        'avg_true': x['unit_sales'].mean(),\n",
    "        'avg_pred': x['pred'].mean(),\n",
    "        'MAE': x['abs_error'].mean(),\n",
    "        'RMSLE': rmsle(x['unit_sales'], x['pred'])\n",
    "    })\n",
    ").round(4)\n",
    "\n",
    "family_metrics = family_metrics.sort_values('RMSLE', ascending=False)\n",
    "print(family_metrics.to_string())\n",
    "\n",
    "# METRICS BY PROMOTION STATUS\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"RMSLE BY PROMOTION STATUS (within 20 items sample)\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "promo_metrics = sample_df.groupby('onpromotion').apply(\n",
    "    lambda x: pd.Series({\n",
    "        'n_records': len(x),\n",
    "        'avg_true': x['unit_sales'].mean(),\n",
    "        'avg_pred': x['pred'].mean(),\n",
    "        'MAE': x['abs_error'].mean(),\n",
    "        'RMSLE': rmsle(x['unit_sales'], x['pred'])\n",
    "    })\n",
    ").round(4)\n",
    "\n",
    "promo_metrics.index = ['No Promo', 'On Promo']\n",
    "print(promo_metrics.to_string())\n",
    "\n",
    "# METRICS BY DAY OF WEEK\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"RMSLE BY DAY OF WEEK (within 20 items sample)\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "dow_names = {0: 'Monday', 1: 'Tuesday', 2: 'Wednesday', 3: 'Thursday', \n",
    "             4: 'Friday', 5: 'Saturday', 6: 'Sunday'}\n",
    "\n",
    "dow_metrics = sample_df.groupby('day_of_week').apply(\n",
    "    lambda x: pd.Series({\n",
    "        'n_records': len(x),\n",
    "        'avg_true': x['unit_sales'].mean(),\n",
    "        'avg_pred': x['pred'].mean(),\n",
    "        'MAE': x['abs_error'].mean(),\n",
    "        'RMSLE': rmsle(x['unit_sales'], x['pred'])\n",
    "    })\n",
    ").round(4)\n",
    "\n",
    "dow_metrics.index = dow_metrics.index.map(dow_names)\n",
    "print(dow_metrics.to_string())\n",
    "\n",
    "# ============================================================\n",
    "# QUICK COMPARISON SUMMARY\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"COMPARISON\")\n",
    "print(\"=\"*90)\n",
    "print(f\"\"\"\n",
    "MODEL: XGboost Final\n",
    "------------------------\n",
    "Overall RMSLE (20 items): {rmsle(sample_df['unit_sales'], sample_df['pred']):.6f}\n",
    "Overall MAE (20 items):   {sample_df['abs_error'].mean():.4f}\n",
    "\n",
    "Best Item RMSLE:  {item_metrics['RMSLE'].min():.4f} (item {item_metrics['RMSLE'].idxmin()})\n",
    "Worst Item RMSLE: {item_metrics['RMSLE'].max():.4f} (item {item_metrics['RMSLE'].idxmax()})\n",
    "Std of Item RMSLE: {item_metrics['RMSLE'].std():.4f}\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
